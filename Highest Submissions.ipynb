{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb63b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Directory paths\n",
    "indir = \"D:/train_small/train_small\"\n",
    "outdir = \"D:/crop\"\n",
    "\n",
    "os.makedirs(outdir)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function that takes the first face (I tried to find a way to get the face with greatest confidence\n",
    "# the dlib library would not work on my computer) This is just a way of avoiding multiple faces per image.\n",
    "def first_face(imgloc, outdir):\n",
    "    # Get the filename of the original image\n",
    "    filename = os.path.basename(imgloc)\n",
    "    # Output path for the cropped or copied image\n",
    "    out_loc = os.path.join(outdir, filename)\n",
    "    # Load each image\n",
    "    try:\n",
    "        img = cv2.imread(imgloc)\n",
    "        # greyscale\n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(grey, 1.1, 4)\n",
    "        # If faces are detected, crop the image to the first detected face\n",
    "        if len(faces) > 0:\n",
    "            x, y, w, h = faces[0]\n",
    "            crop = img[y:y+h, x:x+w]\n",
    "            cv2.imwrite(out_loc, crop)\n",
    "        else:\n",
    "            # If no faces are detected, copy the entire image\n",
    "            shutil.copyfile(imgloc, out_loc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {imgloc}: {str(e)}\")\n",
    "        # Move whole image to output directory if error reading jpg\n",
    "        shutil.copyfile(imgloc, out_loc)\n",
    "        print(f\"Moved unaltered {out_loc}\")\n",
    "\n",
    "for filename in os.listdir(indir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        imgloc = os.path.join(indir, filename)\n",
    "        # Record first face detected\n",
    "        first_face(imgloc, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission 4 ##\n",
    "####################### Unfreezing 15 layers #######################################\n",
    "batch_size = 32\n",
    "\n",
    "# Define dataset directory and CSV file\n",
    "data_dir = \"D:/cropped_faces_copy\"\n",
    "names_csv = \"D:/train_small.csv\"\n",
    "\n",
    "# Create training and validation directories\n",
    "tset = os.path.join(data_dir, \"train\")\n",
    "vset = os.path.join(data_dir, \"val\")\n",
    "os.makedirs(tset, exist_ok=True)\n",
    "os.makedirs(vset, exist_ok=True)\n",
    "\n",
    "# Load the CSV file\n",
    "names = pd.read_csv(names_csv)\n",
    "\n",
    "# Get unique categories (celebrities)\n",
    "cat = names[\"Category\"].unique()\n",
    "\n",
    "# 80/20 training/validation split\n",
    "for cel in cat:\n",
    "    # Make training and validation folders for modeling\n",
    "    os.makedirs(os.path.join(tset, cel), exist_ok=True)\n",
    "    os.makedirs(os.path.join(vset, cel), exist_ok=True)\n",
    "    \n",
    "    # Get filenames for the current category\n",
    "    filenames = names[names[\"Category\"] == cel][\"File Name\"].tolist()\n",
    "    \n",
    "    np.random.shuffle(filenames)\n",
    "    \n",
    "    # Split training and validation\n",
    "    np.random.shuffle(filenames)\n",
    "    train_size = int(len(filenames) * 0.8)\n",
    "    train_filenames = filenames[:train_size]\n",
    "    val_filenames = filenames[train_size:]\n",
    "    \n",
    "    # Copy images to train directory\n",
    "    for filename in train_filenames:\n",
    "        src = os.path.join(data_dir, filename)\n",
    "        dst = os.path.join(tset, cel, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    # Copy images to validation directory\n",
    "    for filename in val_filenames:\n",
    "        src = os.path.join(data_dir, filename)\n",
    "        dst = os.path.join(vset, cel, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "# Image dimensions\n",
    "hei = 160 \n",
    "wid = 160 \n",
    "\n",
    "# Load the MobileNetV2 model with default weights (tmod is the trained model)\n",
    "tmod = MobileNetV2(input_shape=(hei, wid, 3),\n",
    "                            include_top=False,\n",
    "                            weights='imagenet')\n",
    "\n",
    "# Unfreeze specific layers (there are 53 in V2 and I unfreeze the last 15)\n",
    "for layer in tmod.layers[-15:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Final Layer\n",
    "fl = tmod.get_layer('out_relu')\n",
    "fl_out = fl.output\n",
    "\n",
    "# Architecture\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(fl_out)\n",
    "x = tf.keras.layers.Dropout(0.7)(x)\n",
    "x = tf.keras.layers.Dense(len(cat), activation='softmax')(x) \n",
    "model = tf.keras.Model(tmod.input, x)\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Data augmentation -- I could not get keras layers to work on my Jupyter notebook so I used ImageDataGenerator \n",
    "# (I believe ImageDataGenerator is deprecated, but it's in the only data augmentation tool that works on my Jupyter notebook)\n",
    "taug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "vaug = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Augmented data generator\n",
    "t = taug.flow_from_directory(\n",
    "    tset,\n",
    "    target_size=(hei, wid),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "v = vaug.flow_from_directory(\n",
    "    vset,\n",
    "    target_size=(hei, wid),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Training model\n",
    "result = model.fit(t, v, epochs=60, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410fb663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472909df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I cropped the test images in the same manner as the training images but I cannot find that block of code anymore.\n",
    "# It was the same as the code used for the training data above with Cascade\n",
    "from PIL import Image\n",
    "\n",
    "wid = 160\n",
    "hei = 160\n",
    "image_dir = \"D:/test/testcrop\"\n",
    "# Preprocessing\n",
    "def preparation(image):\n",
    "    # Make sure images are RGB\n",
    "    im1 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Resize images\n",
    "    im2 = Image.fromarray(im1)\n",
    "    im3 = im2.resize((wid, hei), Image.ANTIALIAS)\n",
    "    im4 = np.array(im3)\n",
    "    # Put images on 0 to 1 scale\n",
    "    resize_im = im4 / 255.0\n",
    "    # Add batch dimension\n",
    "    proc_im = np.expand_dims(resize_im, axis=0)\n",
    "    return proc_im\n",
    "\n",
    "pred_labels = []\n",
    "\n",
    "# Iterate over images in the input directory\n",
    "for filename in sorted(os.listdir(image_dir)):\n",
    "    # Check if the file is a JPEG image\n",
    "    if filename.lower().endswith(\".jpg\"):\n",
    "        # Get the full path of the image\n",
    "        imgloc = os.path.join(image_dir, filename)\n",
    "        # Attempt to read the image\n",
    "        try:\n",
    "            image = cv2.imread(imgloc)\n",
    "            if image is None:\n",
    "                # If unable to read the image, try searching in the original directory\n",
    "                imgloc = os.path.join(\"D:/test/test\", filename)\n",
    "                image = cv2.imread(imgloc)\n",
    "                if image is None:\n",
    "                    raise Exception(\"Bad image\")\n",
    "            # Predict\n",
    "            prep = preparation(image)\n",
    "            predictions = model.predict(prep)\n",
    "            # Relabel\n",
    "            pred_class = np.argmax(predictions[0])\n",
    "            pred_labels.append(pred_class)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {imgloc}: {str(e)}\")\n",
    "            pred_labels.append(None) \n",
    "\n",
    "# Store Pred\n",
    "pred = pd.DataFrame({\n",
    "    'Id': [os.path.splitext(filename)[0] for filename in sorted(os.listdir(image_dir))],  # Remove file extension\n",
    "    'Category': pred_labels\n",
    "})\n",
    "\n",
    "# Save to submission csv\n",
    "pred.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d55734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf3ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148bac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Number to Celebrity Name\n",
    "sub = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "# Name Directory\n",
    "train_path = \"D:/cropped_faces_copy/train\"\n",
    "celebrity = sorted(os.listdir(train_path))\n",
    "\n",
    "# Sort by jpg number\n",
    "sub = sub.sort_values(by='Id')\n",
    "\n",
    "# Replace the numeric category values with celebrity names\n",
    "sub['Category'] = [celebrity[i] if i >= 0 else None for i in sub['Category']]\n",
    "\n",
    "# Save to final submission csv\n",
    "sub.to_csv(\"submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371ce96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
